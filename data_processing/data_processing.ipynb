{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a462c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_01.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_02.csv (616í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_03.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_04.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_05.csv (682í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_06.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_07.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_08.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_09.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_10.csv (682í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_11.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_12.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_01.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_02.csv (616í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_03.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_04.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_05.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_06.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_07.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_08.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_09.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_10.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_11.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2022_12.csv (682í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_01.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_02.csv (616í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_03.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_04.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_05.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_06.csv (660í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_07.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_08.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_09.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_10.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_11.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_12.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_01.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_02.csv (616í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_03.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_04.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_05.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_06.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_07.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_08.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_09.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_10.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_11.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2023_12.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_01.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_02.csv (667í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_03.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_04.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_05.csv (705í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_06.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_07.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_08.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_09.csv (659í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_10.csv (694í–‰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
      "C:\\Users\\rlarn\\AppData\\Local\\Temp\\ipykernel_6484\\1611909873.py:72: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_11.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_12.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_01.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_02.csv (667í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_03.csv (713í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_04.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_05.csv (705í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_06.csv (660í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_07.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_08.csv (682í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_09.csv (659í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_10.csv (694í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_11.csv (690í–‰)\n",
      "ë¶ˆëŸ¬ì˜´: ë‚¨ë™ë°œì „ëŸ‰_2024_12.csv (713í–‰)\n",
      "ğŸ§¹ ì™„ì „ ë™ì¼í–‰ ì¤‘ë³µ ì œê±°: 48900 â†’ 24450\n",
      "ğŸ” ìºì‹œ íŒŒì¼ ì—†ìŒ â†’ ìƒˆë¡œ í¬ë¡¤ë§ ì‹œì‘\n",
      "ğŸŒ í¬ë¡¤ë§ ì‹œì‘: https://www.koenergy.kr/kosep/hw/fr/ov/ovhw25/main.do?menuCd=FN060202\n",
      "âœ… 35ê°œ í•­ëª© í¬ë¡¤ë§ ì™„ë£Œ â†’ C:/ESG_Project1/merge/cache/namdong_mapping.json\n",
      "ğŸ†• ì§€ì—­ ë³´ì • í…Œì´ë¸” ìƒì„± ì™„ë£Œ â†’ C:/ESG_Project1/merge/cache/region_fix.json\n",
      "\n",
      "ğŸŒ ì¹´ì¹´ì˜¤ APIë¡œ ì§€ì—­ ì¢Œí‘œ ì¡°íšŒ ë° ìµœê·¼ì ‘ ê¸°ìƒê´€ì¸¡ì†Œ ë§¤í•‘ ì‹œì‘...\n",
      " - ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê°•ë¦‰ì‹œ: (37.7521116823526, 128.875906235799) â†’ ìµœê·¼ì ‘ì§€ì  ê°•ë¦‰ (1.33 km)\n",
      " - ê²½ìƒë‚¨ë„ ê³ ì„±êµ°: (34.9730618412549, 128.32236130677) â†’ ìµœê·¼ì ‘ì§€ì  í†µì˜ (17.55 km)\n",
      " - ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ: (35.1802228341536, 128.107706335688) â†’ ìµœê·¼ì ‘ì§€ì  ì§„ì£¼ (3.3 km)\n",
      " - ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ ë§ˆì‚°í•©í¬êµ¬ í•´ìš´ë™: (35.1799611525258, 128.563558712827) â†’ ìµœê·¼ì ‘ì§€ì  ë§ˆì‚° (1.16 km)\n",
      " - ê²½ìƒë¶ë„ êµ¬ë¯¸ì‹œ: (36.1195708487139, 128.344246361062) â†’ ìµœê·¼ì ‘ì§€ì  êµ¬ë¯¸ (2.45 km)\n",
      " - ê²½ìƒë¶ë„ ì˜ˆì²œêµ°: (36.6576538637802, 128.45292491125) â†’ ìµœê·¼ì ‘ì§€ì  ì˜ì£¼ (24.48 km)\n",
      " - ì¸ì²œê´‘ì—­ì‹œ ì˜¹ì§„êµ° ì˜í¥ë©´: (37.2559012375489, 126.483321517933) â†’ ìµœê·¼ì ‘ì§€ì  ì¸ì²œ (27.63 km)\n",
      " - ì „ë¼ë‚¨ë„ ê³ í¥êµ°: (34.6110820210892, 127.284968746855) â†’ ìµœê·¼ì ‘ì§€ì  ê³ í¥ (1.16 km)\n",
      " - ì „ë¼ë‚¨ë„ ê´‘ì–‘ì‹œ: (34.9404252535158, 127.695930772808) â†’ ìµœê·¼ì ‘ì§€ì  ê´‘ì–‘ì‹œ (0.53 km)\n",
      " - ì „ë¼ë‚¨ë„ ì—¬ìˆ˜ì‹œ: (34.7604010648246, 127.662331251572) â†’ ìµœê·¼ì ‘ì§€ì  ì—¬ìˆ˜ (7.53 km)\n",
      " - ì „ë¼ë‚¨ë„ ì¥ì„±êµ°: (35.3018576771346, 126.784918877012) â†’ ìµœê·¼ì ‘ì§€ì  ê³ ì°½ (15.76 km)\n",
      "âœ… ì§€ì—­ ì¢Œí‘œ+ìµœê·¼ì ‘ ê´€ì¸¡ì†Œ ìºì‹œ ì €ì¥ ì™„ë£Œ â†’ C:/ESG_Project1/merge/cache/namdong_geo.json\n",
      "\n",
      "âœ… ìµœì¢… ì™„ë£Œ: C:/ESG_Project1/file/solar_data_file/ë‚¨ë™ë°œì „ëŸ‰_ì§€ì—­ë§¤í•‘_ì‹œê°„í–‰.csv\n",
      "                   ì¼ì‹œ    ë°œì „êµ¬ë¶„        ì§€ì—­  ì§€ì ë²ˆí˜¸  í•©ì‚°ë°œì „ëŸ‰(MWh)\n",
      "0 2022-01-01 00:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00\n",
      "1 2022-01-01 01:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00\n",
      "2 2022-01-01 02:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00\n",
      "3 2022-01-01 03:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00\n",
      "4 2022-01-01 04:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00\n",
      "5 2022-01-01 05:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00\n",
      "6 2022-01-01 06:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00\n",
      "7 2022-01-01 07:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        1.44\n",
      "8 2022-01-01 08:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192       99.36\n",
      "9 2022-01-01 09:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192      294.48\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 0. ê²½ë¡œ ì„¤ì •\n",
    "# ----------------------------------------------------\n",
    "BASE_DIR = \"C:/ESG_Project1/file/solar_data_file/\"\n",
    "CACHE_JSON = \"C:/ESG_Project1/data_processing/json/namdong_mapping.json\"\n",
    "GEO_JSON = \"C:/ESG_Project1/data_processing/json/namdong_geo.json\"\n",
    "REGION_FIX_JSON = \"C:/ESG_Project1/data_processing/json/region_fix.json\"\n",
    "WEATHER_META = \"C:/ESG_Project1/file/KMA_data_file/META_ê´€ì¸¡ì§€ì ì •ë³´.csv\"\n",
    "YEARS = [\"2025\"]\n",
    "\n",
    "OUT_MERGED = os.path.join(BASE_DIR, \"ë‚¨ë™ë°œì „ëŸ‰_ì§€ì—­ë§¤í•‘_ì‹œê°„í–‰.csv\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 1. ë‚¨ë™ë°œì „ ë°œì „ì†Œ ì§€ì—­ ë§¤í•‘ í¬ë¡¤ëŸ¬\n",
    "# ----------------------------------------------------\n",
    "def crawl_mapping():\n",
    "    URL = \"https://www.koenergy.kr/kosep/hw/fr/ov/ovhw25/main.do?menuCd=FN060202\"\n",
    "    print(f\"ğŸŒ í¬ë¡¤ë§ ì‹œì‘: {URL}\")\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    res = requests.get(URL, headers=headers, timeout=10)\n",
    "    res.raise_for_status()\n",
    "    res.encoding = \"utf-8\"\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(\"table\", class_=\"table_list2\")\n",
    "    if len(tables) < 2:\n",
    "        raise RuntimeError(\"âŒ class='table_list2' í…Œì´ë¸”ì´ 2ê°œ ì´ìƒ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "    table = tables[1]\n",
    "\n",
    "    mapping = {}\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        tds = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "        if len(tds) < 2:\n",
    "            continue\n",
    "        ì‚¬ì—…ëª…, ì§€ì—­ = tds[0], tds[1]\n",
    "        if \"íƒœì–‘ê´‘\" not in ì‚¬ì—…ëª…:\n",
    "            continue\n",
    "        ë°œì „êµ¬ë¶„ = ì‚¬ì—…ëª….replace(\"ë°œì „ì†Œ\", \"\").replace(\" \", \"\").strip()\n",
    "        mapping[ë°œì „êµ¬ë¶„] = ì§€ì—­\n",
    "\n",
    "    os.makedirs(os.path.dirname(CACHE_JSON), exist_ok=True)\n",
    "    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(mapping, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"âœ… {len(mapping)}ê°œ í•­ëª© í¬ë¡¤ë§ ì™„ë£Œ â†’ {CACHE_JSON}\")\n",
    "    return mapping\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 2. CSV ìœ í‹¸\n",
    "# ----------------------------------------------------\n",
    "def sniff_delimiter(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read(2048)\n",
    "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "    return \",\" if text.count(\",\") >= text.count(\"\\t\") else \"\\t\"\n",
    "\n",
    "def read_csv_safe(path):\n",
    "    delim = sniff_delimiter(path)\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim, index_col=False)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"cp949\", delimiter=delim, index_col=False)\n",
    "\n",
    "def collect_files():\n",
    "    files = []\n",
    "    for y in YEARS:\n",
    "        folder = os.path.join(BASE_DIR, y)\n",
    "        files += glob(os.path.join(folder, \"*.csv\")) + glob(os.path.join(folder, \"*.CSV\"))\n",
    "    return files\n",
    "\n",
    "def normalize_columns(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"ë°œì „êµ¬ë¶„\" not in df.columns:\n",
    "        expected = [\"ë°œì „êµ¬ë¶„\",\"í˜¸ê¸°\",\"ì¼ì\"] + [f\"{i}ì‹œ ë°œì „ëŸ‰(MWh)\" for i in range(1,25)] + \\\n",
    "                   [\"ì´ëŸ‰(KW)\",\"í‰ê· (KW)\",\"ìµœëŒ€(ì‹œê°„ë³„)\",\"ìµœì†Œ(ì‹œê°„ë³„)\",\"ìµœëŒ€\",\"ìµœì†Œ\"]\n",
    "        df = df.iloc[:, :len(expected)]\n",
    "        df.columns = expected\n",
    "    df[\"ë°œì „êµ¬ë¶„\"] = df[\"ë°œì „êµ¬ë¶„\"].astype(str).str.strip()\n",
    "    df[\"ì¼ì\"] = pd.to_datetime(df[\"ì¼ì\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def get_hour_cols(df):\n",
    "    pat = re.compile(r\"^\\s*(\\d{1,2})ì‹œ\")\n",
    "    return [c for c in df.columns if pat.search(c)]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 3. CSV í†µí•© ë° í˜¸ê¸° í•©ì‚°\n",
    "# ----------------------------------------------------\n",
    "files = collect_files()\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"âš ï¸ CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í´ë” êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "frames = []\n",
    "for f in files:\n",
    "    try:\n",
    "        tmp = read_csv_safe(f)\n",
    "        tmp = normalize_columns(tmp)\n",
    "        tmp[\"íŒŒì¼ì¶œì²˜\"] = os.path.basename(f)\n",
    "        frames.append(tmp)\n",
    "        print(f\"ë¶ˆëŸ¬ì˜´: {os.path.basename(f)} ({len(tmp)}í–‰)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {os.path.basename(f)} ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(f\"ğŸ§¹ ì™„ì „ ë™ì¼í–‰ ì¤‘ë³µ ì œê±°: {before} â†’ {len(df)}\")\n",
    "\n",
    "hour_cols = get_hour_cols(df)\n",
    "long_df = df.melt(\n",
    "    id_vars=[\"ë°œì „êµ¬ë¶„\", \"í˜¸ê¸°\", \"ì¼ì\"],\n",
    "    value_vars=hour_cols,\n",
    "    var_name=\"ì‹œê°„ëŒ€\",\n",
    "    value_name=\"ë°œì „ëŸ‰(MWh)\"\n",
    ")\n",
    "long_df[\"ì‹œê°„\"] = long_df[\"ì‹œê°„ëŒ€\"].str.extract(r\"(\\d{1,2})\").astype(int)\n",
    "long_df[\"ì¼ì‹œ\"] = pd.to_datetime(long_df[\"ì¼ì\"], errors=\"coerce\") + pd.to_timedelta(long_df[\"ì‹œê°„\"] - 1, \"h\")\n",
    "\n",
    "hoqi_sum = (\n",
    "    long_df.groupby([\"ë°œì „êµ¬ë¶„\", \"ì¼ì\", \"ì‹œê°„\"], as_index=False)[\"ë°œì „ëŸ‰(MWh)\"]\n",
    "           .sum(numeric_only=True)\n",
    "           .rename(columns={\"ë°œì „ëŸ‰(MWh)\": \"í•©ì‚°ë°œì „ëŸ‰(MWh)\"})\n",
    ")\n",
    "hoqi_sum[\"ì¼ì‹œ\"] = pd.to_datetime(hoqi_sum[\"ì¼ì\"], errors=\"coerce\") + pd.to_timedelta(hoqi_sum[\"ì‹œê°„\"] - 1, \"h\")\n",
    "hoqi_sum = hoqi_sum[[\"ì¼ì‹œ\", \"ë°œì „êµ¬ë¶„\", \"í•©ì‚°ë°œì „ëŸ‰(MWh)\"]]\n",
    "hoqi_sum = hoqi_sum.sort_values([\"ë°œì „êµ¬ë¶„\", \"ì¼ì‹œ\"]).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 4. ë°œì „ì†Œëª… â†’ ì§€ì—­ ë§¤í•‘ + ë³´ì •í…Œì´ë¸” ì ìš©\n",
    "# ----------------------------------------------------\n",
    "if os.path.exists(CACHE_JSON):\n",
    "    print(f\"ğŸ“¦ ìºì‹œ íŒŒì¼ ë°œê²¬ â†’ {CACHE_JSON}\")\n",
    "    with open(CACHE_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "        mapping = json.load(f)\n",
    "else:\n",
    "    print(\"ğŸ” ìºì‹œ íŒŒì¼ ì—†ìŒ â†’ ìƒˆë¡œ í¬ë¡¤ë§ ì‹œì‘\")\n",
    "    mapping = crawl_mapping()\n",
    "\n",
    "# ğŸ”¹ 4-1. ì§€ì—­ ë³´ì • í…Œì´ë¸” ìë™ ìƒì„±\n",
    "default_region_fix = {\n",
    "    \"ì˜í¥\": \"ì¸ì²œê´‘ì—­ì‹œ ì˜¹ì§„êµ° ì˜í¥ë©´\",\n",
    "    \"ì‚¼ì²œí¬\": \"ê²½ìƒë‚¨ë„ ê³ ì„±êµ°\",\n",
    "    \"ê³ ì„±\": \"ê²½ìƒë‚¨ë„ ê³ ì„±êµ°\",\n",
    "    \"ì˜ˆì²œ\": \"ê²½ìƒë¶ë„ ì˜ˆì²œêµ°\",\n",
    "    \"ì—¬ìˆ˜\": \"ì „ë¼ë‚¨ë„ ì—¬ìˆ˜ì‹œ\",\n",
    "    \"ì˜ë™\": \"ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê°•ë¦‰ì‹œ\",\n",
    "    \"êµ¬ë¯¸\": \"ê²½ìƒë¶ë„ êµ¬ë¯¸ì‹œ\",\n",
    "    \"ì¥ì„±\": \"ì „ë¼ë‚¨ë„ ì¥ì„±êµ°\",\n",
    "    \"ì§„ì£¼\": \"ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ\",\n",
    "    \"ê´‘ì–‘\": \"ì „ë¼ë‚¨ë„ ê´‘ì–‘ì‹œ\",\n",
    "    \"ì°½ì›\": \"ê²½ìƒë‚¨ë„ ì°½ì›ì‹œ ë§ˆì‚°í•©í¬êµ¬ í•´ìš´ë™\",\n",
    "    \"ê³ í¥\": \"ì „ë¼ë‚¨ë„ ê³ í¥êµ°\",\n",
    "    \"êµ°ì‚°\": \"ì „ë¼ë¶ë„ êµ°ì‚°ì‹œ\",\n",
    "    \"ë°€ì–‘\": \"ê²½ìƒë‚¨ë„ ë°€ì–‘ì‹œ\",\n",
    "    \"ì„œì‚°\": \"ì¶©ì²­ë‚¨ë„ ì„œì‚°ì‹œ\",\n",
    "    \"ì˜ì•”\": \"ì „ë¼ë‚¨ë„ ì˜ì•”êµ°\",\n",
    "    \"ì‹ ì•ˆ\": \"ì „ë¼ë‚¨ë„ ì‹ ì•ˆêµ°\",\n",
    "    \"ê°•ë¦‰\": \"ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê°•ë¦‰ì‹œ\",\n",
    "    \"ì „êµ­\": \"ëŒ€í•œë¯¼êµ­\",\n",
    "    \"ì§„ì£¼ ì™¸\": \"ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ ì™¸\"\n",
    "}\n",
    "\n",
    "if not os.path.exists(REGION_FIX_JSON):\n",
    "    os.makedirs(os.path.dirname(REGION_FIX_JSON), exist_ok=True)\n",
    "    with open(REGION_FIX_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(default_region_fix, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"ğŸ†• ì§€ì—­ ë³´ì • í…Œì´ë¸” ìƒì„± ì™„ë£Œ â†’ {REGION_FIX_JSON}\")\n",
    "else:\n",
    "    print(f\"ğŸ“¦ ê¸°ì¡´ ì§€ì—­ ë³´ì • í…Œì´ë¸” ì‚¬ìš© â†’ {REGION_FIX_JSON}\")\n",
    "\n",
    "with open(REGION_FIX_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    region_fix = json.load(f)\n",
    "\n",
    "def normalize_name(name):\n",
    "    name = re.sub(r\"\\s+\", \"\", str(name))\n",
    "    name = name.replace(\"ë°œì „ì†Œ\", \"\").replace(\"íƒœì–‘ê´‘\", \"\").replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "    return name.strip()\n",
    "\n",
    "normalized_mapping = {normalize_name(k): v for k, v in mapping.items()}\n",
    "hoqi_sum[\"ë°œì „êµ¬ë¶„_ì •ê·œí™”\"] = hoqi_sum[\"ë°œì „êµ¬ë¶„\"].apply(normalize_name)\n",
    "\n",
    "keys = list(normalized_mapping.keys())\n",
    "match_cache = {}\n",
    "\n",
    "def fast_match(name):\n",
    "    if name in match_cache:\n",
    "        return match_cache[name]\n",
    "    for key in keys:\n",
    "        if key in name or name in key:\n",
    "            result = normalized_mapping[key]\n",
    "            if result in region_fix:\n",
    "                result = region_fix[result]\n",
    "            match_cache[name] = result\n",
    "            return result\n",
    "    match = process.extractOne(name, keys, scorer=fuzz.partial_ratio)\n",
    "    if match and match[1] >= 75:\n",
    "        result = normalized_mapping[match[0]]\n",
    "        if result in region_fix:\n",
    "            result = region_fix[result]\n",
    "        match_cache[name] = result\n",
    "        return result\n",
    "    match_cache[name] = None\n",
    "    return None\n",
    "\n",
    "mapping_result = {n: fast_match(n) for n in hoqi_sum[\"ë°œì „êµ¬ë¶„_ì •ê·œí™”\"].unique()}\n",
    "hoqi_sum[\"ì§€ì—­\"] = hoqi_sum[\"ë°œì „êµ¬ë¶„_ì •ê·œí™”\"].map(mapping_result)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 5. ì¹´ì¹´ì˜¤ API + ìµœê·¼ì ‘ ê¸°ìƒê´€ì¸¡ì†Œ ë§¤í•‘\n",
    "# ----------------------------------------------------\n",
    "KAKAO_API_KEY = \"93c089f75a2730af2f15c01838e892d3\"\n",
    "KAKAO_URL = \"https://dapi.kakao.com/v2/local/search/address.json\"\n",
    "\n",
    "def get_latlng(address):\n",
    "    headers = {\"Authorization\": f\"KakaoAK {KAKAO_API_KEY}\"}\n",
    "    params = {\"query\": address}\n",
    "    try:\n",
    "        res = requests.get(KAKAO_URL, headers=headers, params=params, timeout=5)\n",
    "        res.raise_for_status()\n",
    "        result = res.json()\n",
    "        if result.get(\"documents\"):\n",
    "            doc = result[\"documents\"][0]\n",
    "            return float(doc[\"y\"]), float(doc[\"x\"])\n",
    "        else:\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì£¼ì†Œ '{address}' ì¡°íšŒ ì‹¤íŒ¨: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# ğŸ”¹ ê¸°ìƒì²­ ê´€ì¸¡ì§€ì  ë©”íƒ€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "weather_df = read_csv_safe(WEATHER_META)\n",
    "weather_df = weather_df.rename(columns=str.strip)\n",
    "weather_df = weather_df[[\"ì§€ì \", \"ì§€ì ëª…\", \"ìœ„ë„\", \"ê²½ë„\"]].dropna(subset=[\"ìœ„ë„\", \"ê²½ë„\"])\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    dlat = math.radians(lat2 - lat1)\n",
    "    dlon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dlat/2)**2 + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2)**2\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "def find_nearest_station(lat, lon, meta_df):\n",
    "    meta_df[\"ê±°ë¦¬(km)\"] = meta_df.apply(\n",
    "        lambda r: haversine(lat, lon, r[\"ìœ„ë„\"], r[\"ê²½ë„\"]), axis=1\n",
    "    )\n",
    "    nearest = meta_df.loc[meta_df[\"ê±°ë¦¬(km)\"].idxmin()]\n",
    "    return {\n",
    "        \"ì§€ì ëª…\": nearest[\"ì§€ì ëª…\"],\n",
    "        \"ì§€ì ë²ˆí˜¸\": int(nearest[\"ì§€ì \"]),\n",
    "        \"ì§€ì ìœ„ë„\": nearest[\"ìœ„ë„\"],\n",
    "        \"ì§€ì ê²½ë„\": nearest[\"ê²½ë„\"],\n",
    "        \"ê±°ë¦¬(km)\": round(nearest[\"ê±°ë¦¬(km)\"], 2)\n",
    "    }\n",
    "\n",
    "if not os.path.exists(GEO_JSON):\n",
    "    print(\"\\nğŸŒ ì¹´ì¹´ì˜¤ APIë¡œ ì§€ì—­ ì¢Œí‘œ ì¡°íšŒ ë° ìµœê·¼ì ‘ ê¸°ìƒê´€ì¸¡ì†Œ ë§¤í•‘ ì‹œì‘...\")\n",
    "    geo_cache = {}\n",
    "\n",
    "    for region in sorted(set(v for v in hoqi_sum[\"ì§€ì—­\"] if v)):\n",
    "        lat, lng = get_latlng(region)\n",
    "        if lat is None or lng is None:\n",
    "            geo_cache[region] = {\"ìœ„ë„\": None, \"ê²½ë„\": None, \"ìµœê·¼ì ‘ê´€ì¸¡ì†Œ\": None}\n",
    "            continue\n",
    "\n",
    "        nearest_station = find_nearest_station(lat, lng, weather_df)\n",
    "        geo_cache[region] = {\n",
    "            \"ìœ„ë„\": lat,\n",
    "            \"ê²½ë„\": lng,\n",
    "            \"ìµœê·¼ì ‘ê´€ì¸¡ì†Œ\": nearest_station\n",
    "        }\n",
    "\n",
    "        print(f\" - {region}: ({lat}, {lng}) â†’ ìµœê·¼ì ‘ì§€ì  {nearest_station['ì§€ì ëª…']} ({nearest_station['ê±°ë¦¬(km)']} km)\")\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    os.makedirs(os.path.dirname(GEO_JSON), exist_ok=True)\n",
    "    with open(GEO_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(geo_cache, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"âœ… ì§€ì—­ ì¢Œí‘œ+ìµœê·¼ì ‘ ê´€ì¸¡ì†Œ ìºì‹œ ì €ì¥ ì™„ë£Œ â†’ {GEO_JSON}\")\n",
    "else:\n",
    "    print(f\"ğŸ“¦ ì¢Œí‘œ ìºì‹œ íŒŒì¼ ì‚¬ìš© â†’ {GEO_JSON}\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 6. ìµœì¢… CSV ì €ì¥ (ì§€ì ë²ˆí˜¸ í¬í•¨)\n",
    "# ----------------------------------------------------\n",
    "with open(GEO_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    geo_cache = json.load(f)\n",
    "\n",
    "def get_station_num(region):\n",
    "    try:\n",
    "        info = geo_cache.get(region)\n",
    "        if info and info.get(\"ìµœê·¼ì ‘ê´€ì¸¡ì†Œ\"):\n",
    "            return info[\"ìµœê·¼ì ‘ê´€ì¸¡ì†Œ\"].get(\"ì§€ì ë²ˆí˜¸\")\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "hoqi_sum[\"ì§€ì ë²ˆí˜¸\"] = hoqi_sum[\"ì§€ì—­\"].apply(get_station_num)\n",
    "hoqi_sum = hoqi_sum[[\"ì¼ì‹œ\", \"ë°œì „êµ¬ë¶„\", \"ì§€ì—­\", \"ì§€ì ë²ˆí˜¸\", \"í•©ì‚°ë°œì „ëŸ‰(MWh)\"]]\n",
    "hoqi_sum.to_csv(OUT_MERGED, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ì™„ë£Œ: {OUT_MERGED}\")\n",
    "print(hoqi_sum.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ ë°œì „ëŸ‰ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°: C:/ESG_Project1/file/solar_data_file/ë‚¨ë™ë°œì „ëŸ‰_ì§€ì—­ë§¤í•‘_ì‹œê°„í–‰.csv\n",
      " - ë¶ˆëŸ¬ì˜´: OBS_ASOS_TIM_2022.csv (831719í–‰)\n",
      " - ë¶ˆëŸ¬ì˜´: OBS_ASOS_TIM_2023.csv (845510í–‰)\n",
      " - ë¶ˆëŸ¬ì˜´: OBS_ASOS_TIM_2024.csv (851256í–‰)\n",
      " - ë¶ˆëŸ¬ì˜´: OBS_ASOS_TIM_2025.csv (634874í–‰)\n",
      "âœ… ê¸°ìƒë°ì´í„° í†µí•© ì™„ë£Œ: 3,163,359í–‰\n",
      "\n",
      "âœ… ìµœì¢… ë³‘í•© ë° NaNâ†’0 ì²˜ë¦¬ ì™„ë£Œ â†’ C:/ESG_Project1/file/solar_data_file/ë‚¨ë™ë°œì „ëŸ‰_ì§€ì—­ë§¤í•‘_ì‹œê°„í–‰_ê¸°ìƒë³‘í•©.csv\n",
      "                   ì¼ì‹œ    ë°œì „êµ¬ë¶„        ì§€ì—­  ì§€ì ë²ˆí˜¸  í•©ì‚°ë°œì „ëŸ‰(MWh)  ê¸°ì˜¨(Â°C)  ê°•ìˆ˜ëŸ‰(mm)  \\\n",
      "0 2022-01-01 00:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00    -3.8      0.0   \n",
      "1 2022-01-01 01:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00    -4.2      0.0   \n",
      "2 2022-01-01 02:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00    -4.8      0.0   \n",
      "3 2022-01-01 03:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00    -5.4      0.0   \n",
      "4 2022-01-01 04:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00    -6.0      0.0   \n",
      "5 2022-01-01 05:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00    -6.3      0.0   \n",
      "6 2022-01-01 06:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        0.00    -7.6      0.0   \n",
      "7 2022-01-01 07:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192        1.44    -7.4      0.0   \n",
      "8 2022-01-01 08:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192       99.36    -7.9      0.0   \n",
      "9 2022-01-01 09:00:00  ê²½ìƒëŒ€íƒœì–‘ê´‘  ê²½ìƒë‚¨ë„ ì§„ì£¼ì‹œ   192      294.48    -5.0      0.0   \n",
      "\n",
      "   ì¼ì¡°(hr)  ì¼ì‚¬(MJ/m2)  \n",
      "0     0.0       0.00  \n",
      "1     0.0       0.00  \n",
      "2     0.0       0.00  \n",
      "3     0.0       0.00  \n",
      "4     0.0       0.00  \n",
      "5     0.0       0.00  \n",
      "6     0.0       0.00  \n",
      "7     0.0       0.00  \n",
      "8     0.0       0.01  \n",
      "9     0.8       0.40  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ ê²½ë¡œ ì„¤ì •\n",
    "# ----------------------------------------------------\n",
    "BASE_DIR = \"C:/ESG_Project1/file/\"\n",
    "SOLAR_CSV = os.path.join(BASE_DIR, \"solar_data_file/ë‚¨ë™ë°œì „ëŸ‰_ì§€ì—­ë§¤í•‘_ì‹œê°„í–‰.csv\")\n",
    "WEATHER_DIR = os.path.join(BASE_DIR, \"KMA/\")\n",
    "OUT_CSV = os.path.join(BASE_DIR, \"solar_data_file/ë‚¨ë™ë°œì „ëŸ‰_ì§€ì—­ë§¤í•‘_ì‹œê°„í–‰_ê¸°ìƒë³‘í•©.csv\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ CSV ì½ê¸° ìœ í‹¸\n",
    "# ----------------------------------------------------\n",
    "def sniff_delimiter(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read(2048)\n",
    "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "    return \",\" if text.count(\",\") >= text.count(\"\\t\") else \"\\t\"\n",
    "\n",
    "def read_csv_safe(path):\n",
    "    delim = sniff_delimiter(path)\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"cp949\", delimiter=delim)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 1. ë°œì „ëŸ‰ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# ----------------------------------------------------\n",
    "print(f\"ğŸ”¹ ë°œì „ëŸ‰ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°: {SOLAR_CSV}\")\n",
    "solar = read_csv_safe(SOLAR_CSV)\n",
    "solar[\"ì¼ì‹œ\"] = pd.to_datetime(solar[\"ì¼ì‹œ\"], errors=\"coerce\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 2. ê¸°ìƒ ë°ì´í„° í†µí•©\n",
    "# ----------------------------------------------------\n",
    "weather_files = sorted(glob(os.path.join(WEATHER_DIR, \"OBS_ASOS_TIM_20*.csv\")))\n",
    "if not weather_files:\n",
    "    raise FileNotFoundError(\"âš ï¸ ê¸°ìƒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "frames = []\n",
    "for wf in weather_files:\n",
    "    try:\n",
    "        tmp = read_csv_safe(wf)\n",
    "        tmp[\"ì¼ì‹œ\"] = pd.to_datetime(tmp[\"ì¼ì‹œ\"], errors=\"coerce\")\n",
    "        tmp = tmp[[\"ì§€ì \", \"ì¼ì‹œ\", \"ê¸°ì˜¨(Â°C)\", \"ê°•ìˆ˜ëŸ‰(mm)\", \"ì¼ì¡°(hr)\", \"ì¼ì‚¬(MJ/m2)\"]]\n",
    "        frames.append(tmp)\n",
    "        print(f\" - ë¶ˆëŸ¬ì˜´: {os.path.basename(wf)} ({len(tmp)}í–‰)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {os.path.basename(wf)} ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "weather = pd.concat(frames, ignore_index=True)\n",
    "print(f\"âœ… ê¸°ìƒë°ì´í„° í†µí•© ì™„ë£Œ: {len(weather):,}í–‰\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 3. ë³‘í•© (ì§€ì ë²ˆí˜¸â†”ì§€ì , ì¼ì‹œ ê¸°ì¤€)\n",
    "# ----------------------------------------------------\n",
    "merged = pd.merge(\n",
    "    solar,\n",
    "    weather,\n",
    "    left_on=[\"ì§€ì ë²ˆí˜¸\", \"ì¼ì‹œ\"],\n",
    "    right_on=[\"ì§€ì \", \"ì¼ì‹œ\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ì¤‘ë³µ ì»¬ëŸ¼ ì œê±°\n",
    "merged = merged.drop(columns=[\"ì§€ì \"], errors=\"ignore\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 4. NaN â†’ 0 ì²˜ë¦¬\n",
    "# ----------------------------------------------------\n",
    "weather_cols = [\"ê¸°ì˜¨(Â°C)\", \"ê°•ìˆ˜ëŸ‰(mm)\", \"ì¼ì¡°(hr)\", \"ì¼ì‚¬(MJ/m2)\"]\n",
    "merged[weather_cols] = merged[weather_cols].fillna(0)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ğŸ”¹ 5. ìµœì¢… CSV ì €ì¥\n",
    "# ----------------------------------------------------\n",
    "merged.to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nâœ… ìµœì¢… ë³‘í•© ë° NaNâ†’0 ì²˜ë¦¬ ì™„ë£Œ â†’ {OUT_CSV}\")\n",
    "print(merged.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
