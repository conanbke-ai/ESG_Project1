{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a462c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m glob\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrapidfuzz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m process, fuzz\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m setup_logger\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import requests\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "from rapidfuzz import process, fuzz\n",
    "from util.logger import setup_logger\n",
    "\n",
    "# ===== 로거 설정 =====\n",
    "logger = setup_logger(__name__)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 🔹 경로 설정\n",
    "# ----------------------------------------------------\n",
    "BASE_DIR = \"C:/ESG_Project1/file/\"\n",
    "KMA_DIR = os.path.join(BASE_DIR, \"KMA_data_file/\")\n",
    "SOLAR_DIR = os.path.join(BASE_DIR, \"solar_data_file/\")\n",
    "OUT_CSV = os.path.join(SOLAR_DIR, \"train_data.csv\")\n",
    "\n",
    "CACHE_JSON = os.path.join(BASE_DIR, \"json/mapping_cache.json\")\n",
    "REGION_FIX_JSON = os.path.join(BASE_DIR, \"json/region_fix.json\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 🔹 공통 유틸\n",
    "# ----------------------------------------------------\n",
    "def sniff_delimiter(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        raw = f.read(2048)\n",
    "    text = raw.decode(\"utf-8\", errors=\"ignore\")\n",
    "    return \",\" if text.count(\",\") >= text.count(\"\\t\") else \"\\t\"\n",
    "\n",
    "\n",
    "def read_csv_safe(path):\n",
    "    delim = sniff_delimiter(path)\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=\"utf-8\", delimiter=delim)\n",
    "    except UnicodeDecodeError:\n",
    "        logger.warning(f\"{path} UTF-8 실패 → cp949로 재시도\")\n",
    "        return pd.read_csv(path, encoding=\"cp949\", delimiter=delim)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 🔹 남동발전 발전소 지역 매핑 크롤러\n",
    "# ----------------------------------------------------\n",
    "def crawl_mapping():\n",
    "    URL = \"https://www.koenergy.kr/kosep/hw/fr/ov/ovhw25/main.do?menuCd=FN060202\"\n",
    "    logger.info(f\"크롤링 시작: {URL}\")\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    res = requests.get(URL, headers=headers, timeout=10)\n",
    "    res.raise_for_status()\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(\"table\", class_=\"table_list2\")\n",
    "    if len(tables) < 2:\n",
    "        logger.error(\"❌ class='table_list2' 테이블이 충분하지 않습니다.\")\n",
    "        raise RuntimeError(\"테이블 부족\")\n",
    "\n",
    "    table = tables[1]\n",
    "    mapping = {}\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        tds = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "        if len(tds) < 2:\n",
    "            continue\n",
    "        name, region = tds[0], tds[1]\n",
    "        if \"태양광\" not in name:\n",
    "            continue\n",
    "        name = name.replace(\"발전소\", \"\").replace(\" \", \"\").strip()\n",
    "        mapping[name] = region\n",
    "\n",
    "    os.makedirs(os.path.dirname(CACHE_JSON), exist_ok=True)\n",
    "    with open(CACHE_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(mapping, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    logger.info(f\"{len(mapping)}개 항목 크롤링 완료 → {CACHE_JSON}\")\n",
    "    return mapping\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 🔹 데이터 처리 함수\n",
    "# ----------------------------------------------------\n",
    "def normalize_columns(df):\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"발전구분\" not in df.columns:\n",
    "        expected = [\"발전구분\", \"호기\", \"일자\"] + [f\"{i}시 발전량(MWh)\" for i in range(1, 25)]\n",
    "        df = df.iloc[:, :len(expected)]\n",
    "        df.columns = expected\n",
    "    df[\"발전구분\"] = df[\"발전구분\"].astype(str).str.strip()\n",
    "    df[\"일자\"] = pd.to_datetime(df[\"일자\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_hour_cols(df):\n",
    "    return [c for c in df.columns if re.match(r\"^\\s*\\d{1,2}시\", c)]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 🔹 전체 처리 파이프라인 (배열 기반)\n",
    "# ----------------------------------------------------\n",
    "def process_all_data():\n",
    "    all_data = {}  # 메모리 내 저장소\n",
    "\n",
    "    # 1️⃣ 발전량 데이터 수집\n",
    "    solar_files = glob(os.path.join(SOLAR_DIR, \"*.csv\")) + glob(os.path.join(SOLAR_DIR, \"*.CSV\"))\n",
    "    if not solar_files:\n",
    "        logger.error(\"CSV 파일이 없습니다.\")\n",
    "        raise FileNotFoundError(\"발전량 CSV 없음\")\n",
    "\n",
    "    solar_frames = []\n",
    "    for f in solar_files:\n",
    "        try:\n",
    "            tmp = read_csv_safe(f)\n",
    "            tmp = normalize_columns(tmp)\n",
    "            tmp[\"파일출처\"] = os.path.basename(f)\n",
    "            solar_frames.append(tmp)\n",
    "            logger.info(f\"불러옴: {os.path.basename(f)} ({len(tmp)}행)\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"{os.path.basename(f)} 실패: {e}\")\n",
    "\n",
    "    df_solar = pd.concat(solar_frames, ignore_index=True)\n",
    "    df_solar = df_solar.drop_duplicates()\n",
    "\n",
    "    # melt 처리\n",
    "    hour_cols = get_hour_cols(df_solar)\n",
    "    df_solar_long = df_solar.melt(\n",
    "        id_vars=[\"발전구분\", \"호기\", \"일자\"],\n",
    "        value_vars=hour_cols,\n",
    "        var_name=\"시간대\",\n",
    "        value_name=\"발전량(MWh)\"\n",
    "    )\n",
    "    df_solar_long[\"시간\"] = df_solar_long[\"시간대\"].str.extract(r\"(\\d{1,2})\").astype(int)\n",
    "    df_solar_long[\"일시\"] = df_solar_long[\"일자\"] + pd.to_timedelta(df_solar_long[\"시간\"] - 1, \"h\")\n",
    "    all_data[\"solar\"] = df_solar_long\n",
    "\n",
    "    # 2️⃣ 지역 매핑 로드\n",
    "    if os.path.exists(CACHE_JSON):\n",
    "        with open(CACHE_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "            mapping = json.load(f)\n",
    "        logger.info(f\"기존 캐시 사용 ({len(mapping)}건)\")\n",
    "    else:\n",
    "        mapping = crawl_mapping()\n",
    "    all_data[\"mapping\"] = mapping\n",
    "\n",
    "    # 3️⃣ 기상 데이터 수집\n",
    "    weather_files = sorted(glob(os.path.join(KMA_DIR, \"OBS_ASOS_TIM_20*.csv\")))\n",
    "    weather_frames = []\n",
    "    for wf in weather_files:\n",
    "        try:\n",
    "            tmp = read_csv_safe(wf)\n",
    "            tmp[\"일시\"] = pd.to_datetime(tmp[\"일시\"], errors=\"coerce\")\n",
    "            tmp = tmp[[\"지점\", \"일시\", \"기온(°C)\", \"강수량(mm)\", \"일조(hr)\", \"일사(MJ/m2)\"]]\n",
    "            weather_frames.append(tmp)\n",
    "            logger.info(f\"기상 불러옴: {os.path.basename(wf)} ({len(tmp)}행)\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{os.path.basename(wf)} 실패: {e}\")\n",
    "    df_weather = pd.concat(weather_frames, ignore_index=True)\n",
    "    all_data[\"weather\"] = df_weather\n",
    "\n",
    "    # 4️⃣ 발전량 + 기상데이터 병합 (메모리 내)\n",
    "    merged = pd.merge(\n",
    "        all_data[\"solar\"],\n",
    "        all_data[\"weather\"],\n",
    "        on=\"일시\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    weather_cols = [\"기온(°C)\", \"강수량(mm)\", \"일조(hr)\", \"일사(MJ/m2)\"]\n",
    "    merged[weather_cols] = merged[weather_cols].fillna(0)\n",
    "    all_data[\"merged_final\"] = merged\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 🔹 실행부\n",
    "# ----------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"=== 데이터 통합 시작 ===\")\n",
    "    all_data = process_all_data()\n",
    "\n",
    "    # 마지막에만 CSV 저장\n",
    "    all_data[\"merged_final\"].to_csv(OUT_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "    logger.info(f\"✅ 최종 병합 완료 → {OUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311.venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
