{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3eaeaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mì›ê²© Jupyter ì„œë²„ 'http://localhost:8889/'ì— ì—°ê²°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ê³  ì—°ê²°í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.(ì›ê²© Jupyter ì„œë²„ 'http://localhost:8889/'ì— ì—°ê²°í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ê³  ì—°ê²°í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.(request to http://localhost:8889/api/kernels?1761604156996 failed, reason: ).)."
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# âœ… CNN-LSTM + Optuna + SHAP íˆíŠ¸ë§µ + ì´ìƒì¹˜ ì œê±° + ì•™ìƒë¸”\n",
    "# =========================================================\n",
    "import os, sys, gc, shap, torch, optuna, platform, logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------\n",
    "# ë¡œê¹…\n",
    "# -------------------------\n",
    "sys.path.append(r\"C:\\ESG_Project1\\util\")\n",
    "from logger import setup_logger\n",
    "logger = setup_logger(__name__)\n",
    "\n",
    "# -------------------------\n",
    "# í™˜ê²½ ì„¤ì •\n",
    "# -------------------------\n",
    "TRAIN_CSV = r\"C:\\ESG_Project1\\file\\merge_data\\train_data.csv\"\n",
    "TEST_CSV  = r\"C:\\ESG_Project1\\file\\merge_data\\test_data.csv\"\n",
    "COL_Y     = \"í•©ì‚°ë°œì „ëŸ‰(MWh)\"\n",
    "COL_TIME  = \"ì¼ì‹œ\"\n",
    "COL_PLANT = \"ë°œì „êµ¬ë¶„\"\n",
    "NUM_FEATS = [\"ê¸°ì˜¨(Â°C)\", \"ê°•ìˆ˜ëŸ‰(mm)\", \"ì¼ì¡°(hr)\", \"ì¼ì‚¬(MJ/m2)\"]\n",
    "SEQ_LEN, HORIZON = 168, 24\n",
    "OUTLIER_FRAC = 0.01\n",
    "SAVE_DIR = r\"C:\\ESG_Project1\\cnn_lstm\\output\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ§© ë°ì´í„° ì „ì²˜ë¦¬ + ì´ìƒì¹˜ ì œê±°\n",
    "# =========================================================\n",
    "def read_csv_auto(path):\n",
    "    try:\n",
    "        df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "    except:\n",
    "        df = pd.read_csv(path, encoding=\"cp949\")\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    for col in NUM_FEATS + [COL_Y]:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.dropna(subset=NUM_FEATS + [COL_Y])\n",
    "    df = df[np.abs(zscore(df[COL_Y])) < 3]  # ì´ìƒì¹˜ ì œê±°\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "train_df = preprocess_data(read_csv_auto(TRAIN_CSV))\n",
    "test_df  = preprocess_data(read_csv_auto(TEST_CSV))\n",
    "logger.info(f\"Train: {train_df.shape}, Test: {test_df.shape}\")\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ”§ Feature Scaling\n",
    "# =========================================================\n",
    "scaler = MinMaxScaler()\n",
    "Xtr = scaler.fit_transform(train_df[NUM_FEATS])\n",
    "Xte = scaler.transform(test_df[NUM_FEATS])\n",
    "ytr = np.log1p(train_df[COL_Y].values)\n",
    "yte = np.log1p(test_df[COL_Y].values)\n",
    "MAX_LOG_Y = float(np.log1p(train_df[COL_Y].quantile(0.999)))\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ§  CNN-LSTM ëª¨ë¸ ì •ì˜\n",
    "# =========================================================\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=128, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(n_features, hidden_size, 3, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_size, HORIZON)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        out, _ = self.lstm(x)\n",
    "        h = self.drop(self.relu(self.fc1(out[:, -1, :])))\n",
    "        y = torch.nn.functional.softplus(self.fc2(h))\n",
    "        return torch.clamp(y, max=MAX_LOG_Y)\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ“¦ Dataset\n",
    "# =========================================================\n",
    "class WindowedDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_len=SEQ_LEN):\n",
    "        self.X, self.y, self.seq_len = X, y, seq_len\n",
    "    def __len__(self):\n",
    "        return len(self.X) - self.seq_len - HORIZON + 1\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.X[idx:idx+self.seq_len]).float(),\n",
    "            torch.tensor(self.y[idx+self.seq_len:idx+self.seq_len+HORIZON]).float()\n",
    "        )\n",
    "\n",
    "# =========================================================\n",
    "# âš™ï¸ Optuna íƒìƒ‰\n",
    "# =========================================================\n",
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 256)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = CNNLSTM(Xtr.shape[1], hidden_size, num_layers, dropout).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    ds = WindowedDataset(Xtr, ytr)\n",
    "    loader = DataLoader(ds, batch_size=128, shuffle=True)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model.train()\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.tensor(Xte[:500]).unsqueeze(1).float().to(DEVICE)\n",
    "        pred = model(X_tensor).cpu().numpy().ravel()\n",
    "        y_true = yte[:len(pred)]\n",
    "        return mean_squared_error(np.expm1(y_true), np.expm1(pred))\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "best_params = study.best_params\n",
    "logger.info(f\"Best Params: {best_params}\")\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ§© ëª¨ë¸ í•™ìŠµ (ì•™ìƒë¸”)\n",
    "# =========================================================\n",
    "models = []\n",
    "for i in range(3):\n",
    "    model = CNNLSTM(Xtr.shape[1], **best_params).to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "    ds = WindowedDataset(Xtr, ytr)\n",
    "    loader = DataLoader(ds, batch_size=128, shuffle=True)\n",
    "\n",
    "    for ep in range(50):\n",
    "        model.train()\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(model(xb), yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    models.append(model)\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ” ì˜ˆì¸¡ + ì„±ëŠ¥\n",
    "# =========================================================\n",
    "def predict(model, X):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X)-SEQ_LEN-HORIZON, HORIZON):\n",
    "            xb = torch.tensor(X[i:i+SEQ_LEN]).unsqueeze(0).float().to(DEVICE)\n",
    "            preds.append(model(xb).cpu().numpy().ravel())\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "preds_list = [predict(m, Xte) for m in models]\n",
    "preds_mean = np.mean(preds_list, axis=0)\n",
    "y_true = np.expm1(yte[:len(preds_mean)])\n",
    "pred_inv = np.expm1(preds_mean)\n",
    "\n",
    "mae = mean_absolute_error(y_true, pred_inv)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, pred_inv))\n",
    "r2 = r2_score(y_true, pred_inv)\n",
    "logger.info(f\"Final Ensemble â†’ MAE={mae:.3f} | RMSE={rmse:.3f} | RÂ²={r2:.4f}\")\n",
    "\n",
    "# =========================================================\n",
    "# ğŸ§  SHAP íˆíŠ¸ë§µ (ì‹œê°„ Ã— íŠ¹ì„±)\n",
    "# =========================================================\n",
    "background = torch.tensor(Xtr[:200]).unsqueeze(1).float().to(DEVICE)\n",
    "test_sample = torch.tensor(Xte[:200]).unsqueeze(1).float().to(DEVICE)\n",
    "explainer = shap.DeepExplainer(models[0], background)\n",
    "shap_values = explainer.shap_values(test_sample)[0]\n",
    "\n",
    "shap_df = pd.DataFrame(np.mean(np.abs(shap_values), axis=1), columns=NUM_FEATS)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(shap_df.T, cmap=\"RdYlBu_r\", annot=False)\n",
    "plt.title(\"SHAP Feature Importance (Time Ã— Feature)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(SAVE_DIR, \"shap_heatmap.png\"), dpi=200)\n",
    "plt.close()\n",
    "\n",
    "logger.info(f\"âœ… SHAP íˆíŠ¸ë§µ ì €ì¥ ì™„ë£Œ: {os.path.join(SAVE_DIR, 'shap_heatmap.png')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python311]",
   "language": "python",
   "name": "conda-env-python311-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
